# -*- coding: utf-8 -*-
"""Submission_Project_Analisis_Data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/NuryaFahruRosyidin2406/Dicoding_Learn-Data-Scientist/blob/main/Submission%20Project%20Analisis%20Data/Submission_Project_Analisis_Data.ipynb

# Submission Project Analisis Data

Pada project kali ini, saya akan menggunakan dataset [E-Commerce Public](https://drive.google.com/file/d/1MsAjPM7oKtVfJL_wRp1qmCajtSG1mdcK/view). Project ini akan mencoba untuk menganalisis data pada dataset tersebut.

## Tahap Pengerjaan sebagai berikut:
1. Tahap Data Wrangling
2. Tahap Exploratory Data Analysis (EDA)
3. Tahap Membuat Visualisasi Data

## 1. Tahap Data Wrangling

### Tahap pengerjaan pada Data Wrangling sebagai berikut:

### A. Tahap Persiapan Library
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

"""### B. Gathering Data

#### Membaca penyimpanan dataset di GitHub
"""

!git clone https://github.com/NuryaFahruRosyidin2406/Dicoding_Learn-Data-Scientist.git

"""#### Memuat / load tabel dari dataset customers.csv"""

customers_df = pd.read_csv("/content/Dicoding_Learn-Data-Scientist/Submission Project Analisis Data/E-commerce-public-dataset/E-Commerce Public Dataset/customers_dataset.csv")
customers_df.head()

"""#### Memuat / load tabel dari dataset geolocation.csv"""

geolocation_df = pd.read_csv("/content/Dicoding_Learn-Data-Scientist/Submission Project Analisis Data/E-commerce-public-dataset/E-Commerce Public Dataset/geolocation_dataset.csv")
geolocation_df.head()

"""#### Memuat / load tabel dari dataset orderItems.csv"""

orderItems_df = pd.read_csv("/content/Dicoding_Learn-Data-Scientist/Submission Project Analisis Data/E-commerce-public-dataset/E-Commerce Public Dataset/order_items_dataset.csv")
orderItems_df.head()

"""#### Memuat / load tabel dari dataset orderPayments.csv"""

orderPayments_df = pd.read_csv("/content/Dicoding_Learn-Data-Scientist/Submission Project Analisis Data/E-commerce-public-dataset/E-Commerce Public Dataset/order_payments_dataset.csv")
orderPayments_df.head()

"""#### Memuat / load tabel dari dataset orderReviews.csv"""

orderReviews_df = pd.read_csv("/content/Dicoding_Learn-Data-Scientist/Submission Project Analisis Data/E-commerce-public-dataset/E-Commerce Public Dataset/order_reviews_dataset.csv")
orderReviews_df.head()

"""#### Memuat / load tabel dari dataset ordersDataset.csv"""

ordersDataset_df = pd.read_csv("/content/Dicoding_Learn-Data-Scientist/Submission Project Analisis Data/E-commerce-public-dataset/E-Commerce Public Dataset/orders_dataset.csv")
ordersDataset_df.head()

"""#### Memuat / load tabel dari dataset productCategoryNameTranslation.csv"""

productCategoryNameTranslation_df = pd.read_csv("/content/Dicoding_Learn-Data-Scientist/Submission Project Analisis Data/E-commerce-public-dataset/E-Commerce Public Dataset/product_category_name_translation.csv")
productCategoryNameTranslation_df.head()

"""#### Memuat / load tabel dari dataset productDataset.csv"""

productDataset_df = pd.read_csv("/content/Dicoding_Learn-Data-Scientist/Submission Project Analisis Data/E-commerce-public-dataset/E-Commerce Public Dataset/products_dataset.csv")
productDataset_df.head()

"""#### Memuat / load tabel dari dataset productDataset.csv"""

sellers_df = pd.read_csv("/content/Dicoding_Learn-Data-Scientist/Submission Project Analisis Data/E-commerce-public-dataset/E-Commerce Public Dataset/sellers_dataset.csv")
sellers_df.head()

"""### C. Assessing Data

#### Menilai data customers_df

Pertama, gunakan method head() dan info() untuk mengecek informasi dan memastikan tipe data tiap kolom dalam customers_df telah sesuai.
"""

customers_df.head(5)

customers_df.info()

"""Berdasarkan informasi dari dataset customers_df, kita bisa ketahui bahwa jumlah data telah lengkap atau dengan kata lain tidak ada missing value di dalamnya.

Jika ingin memastikan apakah terdapat missing value, bisa menggunakan kode berikut
"""

customers_df.isna().sum()

"""Wokay, tidak terdapat missing value

Tahap selanjutnya ialah memeriksa duplikasi dan ringkasan parameter statistik dari customers_df. Berikut merupakan contoh kode untuk melakukannya.
"""

print("Jumlah duplikasi: ", customers_df.duplicated().sum())
customers_df.describe()

"""Berdasarkan informasi tersebut jika kita perhatikan, tidak terdapat keanehan pada hasil tersebut. Ini menunjukkan tidak terdapat duplikasi dan keanehan nilai pada customers_df.

#### Menilai data geolocation_df

Pertama, gunakan method head() dan info() untuk mengecek informasi dan memastikan tipe data tiap kolom dalam geolocation_df telah sesuai.
"""

geolocation_df.head(5)

geolocation_df.info()

"""Berdasarkan informasi dari dataset geolocation_df, kita bisa ketahui bahwa jumlah data telah lengkap atau dengan kata lain tidak ada missing value di dalamnya.

Jika ingin memastikan apakah terdapat missing value, bisa menggunakan kode berikut
"""

geolocation_df.isna().sum()

"""Wokay, tidak terdapat missing value

Tahap selanjutnya ialah memeriksa duplikasi dan ringkasan parameter statistik dari geolocation_df. Berikut merupakan contoh kode untuk melakukannya.
"""

print("Jumlah duplikasi: ", geolocation_df.duplicated().sum())
geolocation_df.describe()

"""Berdasarkan informasi tersebut jika kita perhatikan, terdapat 261831 data yang terduplikasi dan tidak ada keanehan nilai pada geolocation_df selain dari data yang terduplikasi. Pada tahap data cleaning nanti, kita akan menghilangkan semua duplikasi tersebut.

#### Menilai data orderItems_df

Pertama, gunakan method head() dan info() untuk mengecek informasi dan memastikan tipe data tiap kolom dalam ordersItems_df telah sesuai.
"""

orderItems_df.head(5)

orderItems_df.info()

"""Berdasarkan informasi dari dataset orderItems_df, kita bisa ketahui bahwa jumlah data telah lengkap atau dengan kata lain tidak ada missing value di dalamnya. akan tetapi terdapat kesalahan tipe data untuk kolom shipping_limit_date. kolom tersebut harusnya dipresentasikan sebagai tipe data datetime, bukan tipe data object yang digunakan untuk tipe data string. Masalah ini akan kita bersihkan dalam tahap cleaning data

Jika ingin memastikan apakah terdapat missing value, bisa menggunakan kode berikut
"""

orderItems_df.isna().sum()

"""Wokay, tidak terdapat missing value

Tahap selanjutnya ialah memeriksa duplikasi dan ringkasan parameter statistik dari orderItems_df. Berikut merupakan contoh kode untuk melakukannya.
"""

print("Jumlah duplikasi: ", orderItems_df.duplicated().sum())
orderItems_df.describe()

"""Berdasarkan informasi tersebut jika kita perhatikan, tidak terdapat keanehan pada hasil tersebut. Ini menunjukkan tidak terdapat duplikasi dan keanehan nilai pada orderItems_df.

#### Menilai data orderPayments_df

Pertama, gunakan method head() dan info() untuk mengecek informasi dan memastikan tipe data tiap kolom dalam orderPayments_df telah sesuai.
"""

orderPayments_df.head(5)

orderPayments_df.info()

"""Berdasarkan informasi dari dataset orderPayments_df, kita bisa ketahui bahwa jumlah data telah lengkap atau dengan kata lain tidak ada missing value di dalamnya.

Jika ingin memastikan apakah terdapat missing value, bisa menggunakan kode berikut
"""

orderPayments_df.isna().sum()

"""Wokay, tidak terdapat missing value

Tahap selanjutnya ialah memeriksa duplikasi dan ringkasan parameter statistik dari orderPayments_df. Berikut merupakan contoh kode untuk melakukannya.
"""

print("Jumlah duplikasi: ", orderPayments_df.duplicated().sum())
orderPayments_df.describe()

"""Berdasarkan informasi tersebut jika kita perhatikan, tidak terdapat keanehan pada hasil tersebut. Ini menunjukkan tidak terdapat duplikasi dan keanehan nilai pada orderPayments_df.

#### Menilai data orderReviews_df

Pertama, gunakan method head() dan info() untuk mengecek informasi dan memastikan tipe data tiap kolom dalam orderReviews_df telah sesuai.
"""

orderReviews_df.head(5)

orderReviews_df.info()

"""Berdasarkan informasi dari dataset orderReviews_df, kita bisa ketahui bahwa terdapat jumlah missing values pada kolom review_comment_title dan review_comment_message dan terdapat kesalahan tipe data untuk kolom review_creation_date dan review_answer_timestamp. kolom tersebut harusnya dipresentasikan sebagai tipe data datetime, bukan tipe data object yang digunakan untuk tipe data string. Masalah ini akan kita bersihkan dalam tahap cleaning data

Jika ingin memastikan apakah terdapat missing value, bisa menggunakan kode berikut
"""

orderReviews_df.isna().sum()

"""Wokay, benar terdapat missing value

Tahap selanjutnya ialah memeriksa duplikasi dan ringkasan parameter statistik dari orderReviews_df. Berikut merupakan contoh kode untuk melakukannya.
"""

print("Jumlah deuplikat: ", orderReviews_df.duplicated().sum())
orderReviews_df.describe()

"""Berdasarkan informasi tersebut jika kita perhatikan, tidak terdapat keanehan pada hasil tersebut. Ini menunjukkan tidak terdapat duplikasi dan keanehan nilai pada orderReviews_df.

#### Menilai data orderDataset_df

Pertama, gunakan method head() dan info() untuk mengecek informasi dan memastikan tipe data tiap kolom dalam orderDataset_df telah sesuai.
"""

ordersDataset_df.head(5)

ordersDataset_df.info()

"""Berdasarkan informasi dari dataset ordersDataset_df, kita bisa ketahui bahwa terdapat jumlah missing values pada kolom order_approved_at, order_delivered_carrier_date, dan order_delivered_customer_date dan juga terdapat kesalahan tipe data untuk kolom order_purchase_timestamp, order_approved_at, order_delivered_carrier_date, order_delivered_customer_date, dan order_estimated_delivery_date. kolom tersebut harusnya dipresentasikan sebagai tipe data datetime, bukan tipe data object yang digunakan untuk tipe data string. Masalah ini akan kita bersihkan dalam tahap cleaning data

Jika ingin memastikan apakah terdapat missing value, bisa menggunakan kode berikut
"""

ordersDataset_df.isna().sum()

"""Wokay, benar terdapat missing value

Tahap selanjutnya ialah memeriksa duplikasi dan ringkasan parameter statistik dari ordersDataset_df. Berikut merupakan contoh kode untuk melakukannya.
"""

print("Jumlah duplikasi: ", ordersDataset_df.duplicated().sum())
ordersDataset_df.describe()

"""Berdasarkan informasi tersebut jika kita perhatikan, tidak terdapat keanehan pada hasil tersebut. Ini menunjukkan tidak terdapat duplikasi dan keanehan nilai pada ordersDataset_df.

#### Menilai data productCategoryNameTranslation_df

Pertama, gunakan method head() dan info() untuk mengecek informasi dan memastikan tipe data tiap kolom dalam productCategoryNameTranslation_df telah sesuai.
"""

productCategoryNameTranslation_df.head(5)

productCategoryNameTranslation_df.info()

"""Berdasarkan informasi dari dataset geolocation_df, kita bisa ketahui bahwa jumlah data telah lengkap atau dengan kata lain tidak ada missing value di dalamnya.

Jika ingin memastikan apakah terdapat missing value, bisa menggunakan kode berikut
"""

productCategoryNameTranslation_df.isna().sum()

"""Wokay, tidak terdapat missing value

Tahap selanjutnya ialah memeriksa duplikasi dan ringkasan parameter statistik dari productCategoryNameTranslation_df. Berikut merupakan contoh kode untuk melakukannya.
"""

print("Jumlah duplikasi: ", productCategoryNameTranslation_df.duplicated().sum())
productCategoryNameTranslation_df.describe()

"""Berdasarkan informasi tersebut jika kita perhatikan, tidak terdapat keanehan pada hasil tersebut. Ini menunjukkan tidak terdapat duplikasi dan keanehan nilai pada productCategoryNameTranslation_df.

#### Menilai data productDataset_df

Pertama, gunakan method head() dan info() untuk mengecek informasi dan memastikan tipe data tiap kolom dalam productDataset_df telah sesuai.
"""

productDataset_df.head(5)

productDataset_df.info()

"""Berdasarkan informasi dari dataset productDataset_df, kita bisa ketahui bahwa terdapat jumlah missing values pada banyak kolom dan tidak terdapat kesalahan tipe data pada kolom. Masalah ini akan kita bersihkan dalam tahap cleaning data

Jika ingin memastikan apakah terdapat missing value, bisa menggunakan kode berikut
"""

productDataset_df.isna().sum()

"""Wokay, benar terdapat missing value

Tahap selanjutnya ialah memeriksa duplikasi dan ringkasan parameter statistik dari productDataset_df. Berikut merupakan contoh kode untuk melakukannya.
"""

print("Jumlah duplikasi: ", productDataset_df.duplicated().sum())
productDataset_df.describe()

"""Berdasarkan informasi tersebut jika kita perhatikan, tidak terdapat keanehan pada hasil tersebut. Ini menunjukkan tidak terdapat duplikasi dan keanehan nilai pada productDataset_df.

#### Menilai data sellers_df

Pertama, gunakan method head() dan info() untuk mengecek informasi dan memastikan tipe data tiap kolom dalam sellers_df telah sesuai.
"""

sellers_df.head(5)

sellers_df.info()

"""Berdasarkan informasi dari dataset geolocation_df, kita bisa ketahui bahwa jumlah data telah lengkap atau dengan kata lain tidak ada missing value di dalamnya.

Jika ingin memastikan apakah terdapat missing value, bisa menggunakan kode berikut
"""

sellers_df.isna().sum()

"""Wokay, tidak terdapat missing value

Tahap selanjutnya ialah memeriksa duplikasi dan ringkasan parameter statistik dari sellers_df. Berikut merupakan contoh kode untuk melakukannya.
"""

print("Jumlah duplikasi: ", sellers_df.duplicated().sum())
sellers_df.describe()

"""Berdasarkan informasi tersebut jika kita perhatikan, tidak terdapat keanehan pada hasil tersebut. Ini menunjukkan tidak terdapat duplikasi dan keanehan nilai pada sellers_df.

### D. Cleaning Data

Nah, sekarang kita akan memasuki proses terakhir dalam data wrangling yaitu pembersihan atau cleaning data. Pada tahap ini, kita akan membersihkan berbagai masalah yang telah teridentifikasi dalam proses assessing data.

#### Membersihkan Data geolocation_df

Pertama, gunakan method head() dan info() untuk mengecek informasi dan memastikan tipe data pada dataset.
"""

geolocation_df.head(3)

geolocation_df.info()

"""##### Menghilangkan duplicate data"""

geolocation_df.drop_duplicates(inplace=True)

print("Jumlah duplikasi: ", geolocation_df.duplicated().sum())

"""okay, cleaning pada dataset geolocation_df sudah siap

#### Membersihkan Data orderItems_df

Pertama, gunakan method head() dan info() untuk mengecek informasi dan memastikan tipe data pada dataset.
"""

orderItems_df.head(3)

orderItems_df.info()

"""##### Memperbaiki kesalahan tipe data untuk kolom shipping_limit_date dan mengganti tipe data nya menjadi datetime"""

datetime_columns = ["shipping_limit_date"]

for column in datetime_columns:
  orderItems_df[column] = pd.to_datetime(orderItems_df[column])

orderItems_df.info()

"""okay, cleaning pada dataset orderItems_df sudah siap

#### Membersihkan Data orderReviews_df

Pertama, gunakan method head() dan info() untuk mengecek informasi dan memastikan tipe data pada dataset.
"""

orderReviews_df.head(3)

orderReviews_df.info()

"""##### Memperbaiki kesalahan tipe data untuk kolom review_creation_date dan review_answer_timestamp dan mengganti tipe data nya menjadi datetime"""

datetime_columns = ["review_creation_date", "review_answer_timestamp"]

for column in datetime_columns:
  orderReviews_df[column] = pd.to_datetime(orderReviews_df[column])

orderReviews_df.info()

"""##### Menangani missing value"""

orderReviews_df.isna().sum()

"""Karena kolom review_comment_message dan review_comment_message sama-sama tipe data String atau Dtype object dan sama-sama pesan review. Kita bisa isikan value yang sama

###### Missing value pada review_comment_title dan review_comment_message
"""

orderReviews_df[orderReviews_df.review_comment_title.isna()]

orderReviews_df[orderReviews_df.review_comment_message.isna()]

"""Karena masih banyak informasi yang berharga pada dataset tersebut, kita gunakan metode imputating untuk menangani missing value"""

orderReviews_df.review_comment_title.value_counts()

orderReviews_df.review_comment_message.value_counts()

"""Karena value dari review_comment_title dan review_comment_message banyak yang acak, sehingga saya pilih value secreto yang artinya rahasia"""

orderReviews_df.fillna(value="secreto", inplace=True)

"""cek kembali apakah ada missing value"""

orderReviews_df.isna().sum()

"""okay, cleaning pada dataset orderReviews_df sudah siap

#### Membersihkan Data ordersDataset_df

Pertama, gunakan method head() dan info() untuk mengecek informasi dan memastikan tipe data pada dataset.
"""

ordersDataset_df.head(3)

ordersDataset_df.info()

"""##### Menangani missing value"""

ordersDataset_df.isna().sum()

"""Cek missing value pada tiap kolom yang missing value"""

ordersDataset_df[ordersDataset_df.order_approved_at.isna()]

ordersDataset_df[ordersDataset_df.order_delivered_carrier_date.isna()]

ordersDataset_df[ordersDataset_df.order_delivered_customer_date.isna()]

"""Karena informasi pada dataset tersebut kebanyakan tanggal, cukup berharga, dan menurut saya bisa di drop data, kita gunakan metode dropping untuk menangani missing value"""

ordersDataset_df.dropna(axis=0, inplace=True)

"""cek kembali apakah ada missing value"""

ordersDataset_df.isna().sum()

"""##### Memperbaiki kesalahan tipe data untuk kolom order_purchase_timestamp, order_approved_at, order_delivered_carrier_date, order_delivered_customer_date, dan order_estimated_delivery_date dan mengganti tipe data nya menjadi datetime"""

ordersDataset_df.info()

datetime_columns = ["order_purchase_timestamp", "order_approved_at", "order_delivered_carrier_date", "order_delivered_customer_date", "order_estimated_delivery_date"]

for column in datetime_columns:
  ordersDataset_df[column] = pd.to_datetime(ordersDataset_df[column])

ordersDataset_df.info()

"""okay, cleaning pada dataset orderReviews_df sudah siap

#### Membersihkan Data productDataset_df

Pertama, gunakan method head() dan info() untuk mengecek informasi dan memastikan tipe data pada dataset.
"""

productDataset_df.head(3)

productDataset_df.info()

"""##### Menangani missing value

mengecek kembali dataset yang missing
"""

productDataset_df.isna().sum()

productDataset_df[productDataset_df.product_category_name.isna()]

"""Setelah saya amati karena informasi pada dataset tersebut kebanyakan beragam di setiap kolom dan tidak memiliki pola yang tidak cukup jelas. Menurut saya bisa di drop data, oleh karena itu, kita gunakan metode dropping untuk menangani missing value"""

productDataset_df.dropna(axis=0, inplace=True)

productDataset_df.isna().sum()

productDataset_df.info()

productDataset_df.head(3)

"""okay, cleaning pada dataset productDataset_df sudah siap

## 2. Tahap Exploratory Data Analysis (EDA)

### Menentukan Pertanyaan Bisnis Untuk Explorasi Data

Pada project ini merupakan sebuah kasus dari E-Commerce Public. Adapun beberapa pertanyaan bisnis seperti berikut:
1. Bagaimana performa penjualan dan revenue perusahaan dalam beberapa bulan terakhir?
2. Produk apa yang banyak dan paling sedikit di order?

Ok, setelah kita dapatkan pertanyaan bisnis tersebut yang harus kita jawab melalui proses analisis data.

### Melakukan Eksplorasi data

#### Pertama-tama kita gunakan method head() untuk mengecek informasi kolom pada masing-masing dataset.
"""

customers_df.head(3)

geolocation_df.head(3)

orderItems_df.head(3)

orderPayments_df.head(3)

orderReviews_df.head(3)

ordersDataset_df.head(3)

productCategoryNameTranslation_df.head(3)

productDataset_df.head(3)

sellers_df.head(3)

"""#### Eksplorasi Data customers_df"""

customers_df.describe(include="all")

"""Berdasarkan rangkuman parameter statistik diatas, kita akan memperoleh persebaran jumlah pelanggan berdasarkan kota (customer_city) dan negara bagian (customer_state) yang kedua kolom tersebut dikenali sebagai tipe data object atau string. Kita akan method groupby() dan sort_values() secara decending agar hasilnya lebih mudah untuk dilihat.

Sebagai tambahannya yaitu terdapat kolom customer_id yang dapat dihubungkan dengan kolom dataset lain yang sama.

Sekarang kita lihat demografi pelanggan (customer_id) berdasarkan kota (customer_city) dan negara bagian (customer_state)
"""

customers_df.groupby(by="customer_city").customer_id.nunique().sort_values(ascending=False)

customers_df.groupby(by="customer_state").customer_id.nunique().sort_values(ascending=False)

"""Berdasarkan informasi tersebut kita dapat melihat bahwa persebaran jumlah pelanggan berdasarkan kota (customer_city) paling banyak berada di Sao Paulo dan paling banyak berasal dari negara bagian (customer_state) dengan kode SP.

#### Eksplorasi Data geolocation_df
"""

geolocation_df.describe(include="all")

"""Berdasarkan rangkuman parameter statistik di atas, kita dapat memperoleh informasi geolocation dari kota dan negara bagian yang kedua kolom tersebut dikenali sebagai tipe data object atau string. Kita akan method groupby() dan sort_values() secara decending agar hasilnya lebih mudah untuk dilihat.

Sekarang kita lihat demografi banyaknya geolocation_zip_code_prefix berdasarkan kota (geolocation_city) dan negara bagian (geolocation_state)
"""

geolocation_df.groupby(by="geolocation_city").geolocation_zip_code_prefix.nunique().sort_values(ascending=False)

geolocation_df.groupby(by="geolocation_state").geolocation_zip_code_prefix.nunique().sort_values(ascending=False)

"""Berdasarkan informasi tersebut kita dapat melihat bahwa persebaran code prefix berdasarkan kota (customer_city) paling banyak berada di Sao Paulo dan paling banyak berasal dari negara bagian (customer_state) dengan kode SP.

#### Eksplorasi Data orderItems_df
"""

orderItems_df.describe(include="all")

"""Berdasarkan rangkuman parameter statistik diatas, kita memperoleh informasi dari masing-masing order_id, product_id, seller_id, dan price yang dapat kita hubungkan dengan dataset lainnya.

#### Eksplorasi Data orderPayments_df
"""

orderPayments_df.describe(include="all")

"""Berdasarkan rangkuman parameter statistik diatas, kita memperoleh informasi dari masing-masing order_id yang dapat kita hubungkan dengan dataset lainnya. Kita akan method groupby() dan sort_values() secara decending agar hasilnya lebih mudah untuk dilihat.

Sekarang kita lihat demografi banyaknya order_id berdasarkan jenis pembayaran (payment_type)
"""

orderPayments_df.groupby(by="payment_type").order_id.nunique().sort_values(ascending=False)

"""Berdasarkan informasi tersebut kita dapat melihat bahwa banyak order customer menggunakan jenis pembayaran credit card yang berada di urutan pertama dan di urutan selanjutnya menggunakan jenis pembayaran boleto.

#### Eksplorasi Data orderReviews_df
"""

orderReviews_df.describe(include="all")

"""Berdasarkan rangkuman parameter statistik diatas, kita memperoleh informasi dari masing-masing order_id yang dapat kita hubungkan dengan dataset lainnya. Kita akan method groupby() dan sort_values() secara decending agar hasilnya lebih mudah untuk dilihat.

Sekarang kita lihat demografi order_id berdasarkan banyaknya tingkat kepuasan ()review_score.
"""

orderReviews_df.groupby(by="review_score").order_id.nunique().sort_values(ascending=False)

"""Berdasarkan informasi tersebut kita dapat melihat bahwa banyak pelanggan (order_id) yang memberikan review_score 5 dan 4, akan tetapi banyak juga yang merasa kurang puas yang memberikan review_score 1.

#### Eksplorasi Data ordersDataset_df
"""

ordersDataset_df.describe(include="all")

"""Berdasarkan rangkuman parameter statistik diatas, kita memperoleh informasi dari masing-masing order_id dan customer_id yang dapat kita hubungkan dengan dataset lainnya.

#### Menggabungkan Data orderItems_df dan orderPayments_df

Untuk memperoleh lebih banyak informasi terkait kedua data tersebut, kita perlu menggabungkan keduanya mmelalui proses join atau merge.
"""

orderItems_orderPayments_df = pd.merge(
    left = orderItems_df,
    right = orderPayments_df,
    how = "left",
    left_on = "order_id",
    right_on = "order_id"
)

orderItems_orderPayments_df.head()

"""#### Menggabungkan Data orderItems_orderPayments_df dan orderReviews_df

Untuk memperoleh lebih banyak informasi terkait kedua data tersebut, kita perlu menggabungkan keduanya mmelalui proses join atau merge.
"""

orderItems_orderPayments_orderReviews_df = pd.merge(
    left = orderItems_orderPayments_df,
    right = orderReviews_df,
    how = "left",
    left_on = "order_id",
    right_on = "order_id"
)

orderItems_orderPayments_orderReviews_df.head()

"""#### Menggabungkan Data orderItems_orderPayments_orderReviews_df dan ordersDataset_df

Untuk memperoleh lebih banyak informasi terkait kedua data tersebut, kita perlu menggabungkan keduanya mmelalui proses join atau merge.
"""

orderItems_orderPayments_orderReviews_ordersDataset_df = pd.merge(
    left = orderItems_orderPayments_orderReviews_df,
    right = ordersDataset_df,
    how = "left",
    left_on = "order_id",
    right_on = "order_id"
)

orderItems_orderPayments_orderReviews_ordersDataset_df.head()

"""#### Menggabungkan Data orderItems_orderPayments_orderReviews_ordersDataset_df dan customers_df

Untuk memperoleh lebih banyak informasi terkait kedua data tersebut, kita perlu menggabungkan keduanya mmelalui proses join atau merge.
"""

order_IPRD_customers_df = pd.merge(
    left = customers_df,
    right = orderItems_orderPayments_orderReviews_ordersDataset_df,
    how = "left",
    left_on = "customer_id",
    right_on = "customer_id"
)

order_IPRD_customers_df.head()

"""#### Eksplorasi Data productCategoryNameTranslation_df"""

productCategoryNameTranslation_df.describe(include="all")

"""Berdasarkan rangkuman parameter statistik diatas, kita memperoleh informasi dari kolom product_category_name yang dapat kita hubungkan dengan dataset lainnya.

#### Eksplorasi Data productDataset_df
"""

productDataset_df.describe(include="all")

"""Berdasarkan rangkuman parameter statistik diatas, kita memperoleh informasi dari kolom product_id dan product_category_name yang dapat kita hubungkan dengan dataset lainnya.

#### Menggabungkan Data productCategoryNameTranslation_df dan productDataset_df

Untuk memperoleh lebih banyak informasi terkait kedua data tersebut, kita perlu menggabungkan keduanya mmelalui proses join atau merge.
"""

productCategoryNameTranslation_productDataset_df = pd.merge(
    left = productDataset_df,
    right = productCategoryNameTranslation_df,
    how = "left",
    left_on = "product_category_name",
    right_on = "product_category_name"
)

productCategoryNameTranslation_productDataset_df.head()

"""#### Menggabungkan Data productCategoryNameTranslation_productDataset_df dan order_IPRD_customers_df

Untuk memperoleh lebih banyak informasi terkait kedua data tersebut, kita perlu menggabungkan keduanya mmelalui proses join atau merge.
"""

order_IPRD_customers_product_df = pd.merge(
    left = productCategoryNameTranslation_productDataset_df,
    right = order_IPRD_customers_df,
    how = "left",
    left_on = "product_id",
    right_on = "product_id"
)

order_IPRD_customers_product_df.head()

order_IPRD_customers_product_df.info()

"""Eksplorasi Data sellers_df"""

sellers_df.describe(include="all")

"""Berdasarkan rangkuman parameter statistik diatas, kita memperoleh informasi dari kolom seller_id yang dapat kita hubungkan dengan dataset lainnya.

#### Menggabungkan Data order_IPRD_customers_product_df dan sellers_df

Untuk memperoleh lebih banyak informasi terkait kedua data tersebut, kita perlu menggabungkan keduanya mmelalui proses join atau merge.
"""

all_kq_df = pd.merge(
    left = order_IPRD_customers_product_df,
    right = sellers_df,
    how = "left",
    left_on = "seller_id",
    right_on = "seller_id"
)

all_kq_df.head()

all_kq_df.info()

geolocation_df.info()

"""#### Eksplorasi Data all_kq_df dataset gabungan"""

all_kq_df.describe(include="all")

all_kq_df.info()

"""Selanjutnya, mari kita coba lihat preferensi pembelian berdasarkan customer_city dan product_category_name"""

all_kq_df.groupby(by=["customer_city", "product_category_name"]).agg({
    "payment_value": "sum",
    "review_score": "sum"
})

"""Pada Pivot tabel diatas memberikan kita gambaran terkait produk yang disukai pengguna berdasarkan lokasi kotanya.

## 3. Tahap Membuat Visualisasi Data

### Membuat Visualisasi Data Yang Menjawab Pertanyaan Bisnis

Pada project ini merupakan sebuah kasus dari E-Commerce Public. Adapun beberapa pertanyaan bisnis seperti berikut:
1. Bagaimana performa penjualan dan revenue perusahaan dalam beberapa bulan terakhir?
2. Produk apa yang banyak dan palinng sedikit di order?

Nah, sekarang tugas kita adalah membuat visualisasi data dan explanatory analysis guna menjawab berbagai pertanyaan tersebut.

#### 1. Bagaimana performa penjualan dan revenue perusahaan dalam beberapa bulan terakhir?

Untuk menjawab pertanyaan pertama, kita perlu membuat sebuah DataFrame baru untuk menampung informasi terkait jumlah order dan total revenue yang diperoleh pada tiap bulannya. Oleh karena itu, kita perlu mengubah frekuensi dari data yang awalnya harian menjadi bulanan.
"""

all_kq_df.info()

monthly_orders_df = all_kq_df.resample(rule = 'M', on = 'order_approved_at').agg({
    "order_id": "nunique",
    "payment_value": "sum"
})

monthly_orders_df.index = monthly_orders_df.index.strftime('%Y-%m')
monthly_orders_df = monthly_orders_df.reset_index()
monthly_orders_df.rename(columns={
    "order_id": "order_count",
    "payment_value": "revenue"
}, inplace=True)

monthly_orders_df.head()

"""Oke, sekarang kita telah memiliki sebuah DataFrame yang memuat informasi yang dibutuhkan untuk menjawab pertanyaan pertama ini. Namun, untuk mempermudah orang lain dalam memahami informasi dari DataFrame tersebut, kita perlu membuat visualisasi datanya."""

monthly_orders_df = all_kq_df.resample(rule = 'M', on = 'order_approved_at').agg({
    "order_id": "nunique",
    "payment_value": "sum"
})
#mengubah format order date menjadi nama bulan
monthly_orders_df.index = monthly_orders_df.index.strftime('%B')

monthly_orders_df = monthly_orders_df.reset_index()
monthly_orders_df.rename(columns={
    "order_id": "order_count",
    "payment_value": "revenue"
}, inplace=True)

plt.figure(figsize=(12, 6))
plt.plot(monthly_orders_df["order_approved_at"], monthly_orders_df["order_count"], marker='o', linewidth=1, color="#72BCD4")
# plt.plot(range(len(monthly_orders_df["order_approved_at"])), monthly_orders_df["order_count"], marker = 'o', linewidth = 1, color = "#72BCD4")
# plt.plot(range(len(monthly_orders_df["order_approved_at"])), monthly_orders_df["order_count"], marker='o', linewidth=1, color="#72BCD4")
plt.title("Number of Orders per Month (2016 - 2017)", loc="center", fontsize=20)
plt.xticks(rotation=45, ha="right", fontsize=10)
# plt.xticks(range(len(monthly_orders_df)), monthly_orders_df.index, rotation=45, ha="right", fontsize=10)
plt.yticks(fontsize=10)
plt.show()

plt.figure(figsize=(12, 6))
plt.plot(range(len(monthly_orders_df["order_approved_at"])), monthly_orders_df["order_count"], marker = 'o', linewidth = 1, color = "#72BCD4")
plt.title("Number of Orders per Month (2016 - 2017)", loc="center", fontsize=20)
plt.xticks(range(len(monthly_orders_df)), monthly_orders_df.index, rotation=45, ha="right", fontsize=10)
plt.yticks(fontsize=10)
plt.show()

"""Berdasarkan visualisasi diatas, kita dapat melihat bahwa jumlah order terbanyak di value 70000 an yang terjadi pada bulan November tahun 2017 dan jumlah order pada bulan selanjutnya (November 2017) mengalami value dengan rata-rata sekitar 6000 an.

#### 2. Produk apa yang banyak dan paling sedikit di order?

Pada pertanyaan bisnis selanjutnya, kita ingin mengidentifikasi produk dengan penjualan terbanyak dan paling sedikit. Untuk melakukan ini, tentunya kita harus membuat sebuah DataFrame baru guna menampung informasi terkait jumlah penjualan tiap produk.
"""

sum_order_items_df = all_kq_df.groupby("product_category_name").order_id.nunique().sort_values(ascending=False).reset_index()
sum_order_items_df.head(15)

"""Untuk mempermudah kita dalam menyampaikan informasi tersebut, kita harus membuat visualisasi data dalam bentuk bar chart. Selain itu, untuk mempermudah orang lain dalam mengidentifikasi produk dengan performa terbaik dan terburuk, kita perlu membuat dua buah visualisasi data dalam satu gambar visual."""

fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(24, 6))

colors = ["#72BCD4", "#D3D3D3", "#D3D3D3", "#D3D3D3", "#D3D3D3"]

sns.barplot(x="order_id", y="product_category_name", data=sum_order_items_df.head(5), palette=colors, ax=ax[0])
ax[0].set_ylabel(None)
ax[0].set_xlabel(None)
ax[0].set_title("Best Performing Product", loc="center", fontsize=15)
ax[0].tick_params(axis ='y', labelsize=12)

sns.barplot(x="order_id", y="product_category_name", data=sum_order_items_df.sort_values(by="order_id", ascending=True).head(5), palette=colors, ax=ax[1])
ax[1].set_ylabel(None)
ax[1].set_xlabel(None)
ax[1].invert_xaxis()
ax[1].yaxis.set_label_position("right")
ax[1].yaxis.tick_right()
ax[1].set_title("Worst Performing Product", loc="center", fontsize=15)
ax[1].tick_params(axis='y', labelsize=12)

plt.suptitle("Best and Worst Performing Product by Number of Orders", fontsize=20)
plt.show()

"""Berdasarkan gambar di atas, Anda dapat melihat bahwa produk Denim merupakan produk yang paling laris. Kontras dengan hal tersebut, produk Mandarin Collar merupakan produk yang paling sedikit terjual."""

all_kq_df.to_csv("all_data.csv", index=False)